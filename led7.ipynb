{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LED PATTERNS for the digits 0 to 9\n",
    "LED_BLUE_PRINT = np.array([[1,1,1,1,1,1,0],\n",
    "                     [0,1,1,0,0,0,0],\n",
    "                     [1,1,0,1,1,0,1],\n",
    "                     [1,1,1,1,0,0,1],\n",
    "                     [0,0,1,0,0,1,1],\n",
    "                     [1,0,1,1,0,1,1],\n",
    "                     [1,0,1,1,1,1,1],\n",
    "                     [1,1,1,0,0,0,0],\n",
    "                     [1,1,1,1,1,1,1],\n",
    "                     [1,1,1,1,0,1,1]\n",
    "                    ])\n",
    "\n",
    "# All cases essential data files\n",
    "TRAIN_DATA_FILE = \"train_data.csv\"\n",
    "TEST_DATA_FILE = \"test_data.csv\"\n",
    "ALL_CASES_INPUT_DATA = \"all_cases_input_data.csv\"\n",
    "ALL_CASES_PREDICTIONS = \"all_cases_predictions.csv\"\n",
    "ALL_CASES_PREDICTIONS_COLUMS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "# LEDS and DIGITS arr to refer\n",
    "LEDS_ARR = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "DIGITS = [\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic data loading function\n",
    "def load_data(file=TRAIN_DATA_FILE, header=True):\n",
    "    csv_path = os.path.join(\"\", file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "# Drop DIGIT column and treat it as labels\n",
    "train_data = load_data(TRAIN_DATA_FILE)\n",
    "train_labels = train_data[\"DIGIT\"]\n",
    "train_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "test_data = load_data(TEST_DATA_FILE)\n",
    "test_labels = test_data[\"DIGIT\"]\n",
    "test_data.drop(\"DIGIT\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all cases input data\n",
    "all_cases_input_data = load_data(ALL_CASES_INPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the optimal dimensions using PCA\n",
    "# Return dimension where the minimum variance between the features drop to thres value\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_optimum_dimensions(x, thres=0.01):\n",
    "    pca = PCA(n_components=1.0 - thres)\n",
    "    pca.fit(x)\n",
    "    optimum_dim = pca.n_components_\n",
    "    return optimum_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data processing routine\n",
    "\n",
    "def process_data(x, y, poly_features=None, pca=None, OPTIMUM_DIMENSION=None, scalar=None):\n",
    "    training_features = x.copy()\n",
    "    testing_features = y.copy()\n",
    "    \n",
    "    if poly_features == None:\n",
    "        poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        poly_features.fit(training_features)\n",
    "        \n",
    "    training_features = poly_features.transform(training_features)\n",
    "    testing_features = poly_features.transform(testing_features)\n",
    "    \n",
    "    if scalar == None:\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(training_features)\n",
    "        \n",
    "    training_features = scalar.transform(training_features)\n",
    "    testing_features = scalar.transform(testing_features)\n",
    "\n",
    "    if OPTIMUM_DIMENSION == None:\n",
    "        OPTIMUM_DIMENSION = get_optimum_dimensions(x=training_features, thres=0.0001)\n",
    "        print(\"Optimum Dimensions: \", OPTIMUM_DIMENSION)\n",
    "\n",
    "    if pca == None:  \n",
    "        pca = PCA(random_state=42, n_components=OPTIMUM_DIMENSION)\n",
    "        pca.fit(training_features)\n",
    "        \n",
    "    training_features = pca.transform(training_features)\n",
    "    testing_features = pca.transform(testing_features)\n",
    "    \n",
    "    return training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Dimensions:  9\n"
     ]
    }
   ],
   "source": [
    "training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, scalar = process_data(x=train_data, y=test_data)\n",
    "\n",
    "training_labels = train_labels.values\n",
    "testing_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.17857142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = False\n",
    "if gridSearch:\n",
    "    parameters = {\n",
    "                  'n_iter' : [2,3,4,5,6,7,8,9,10]\n",
    "                 }\n",
    "    clf = GridSearchCV(SGDClassifier(random_state=42), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, penalty=\"elasticnet\", loss='log', n_iter=3)\n",
    "cross_val_scores = cross_val_score(clone(sgd_clf), X_train, Y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_scores)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == sgd_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = False\n",
    "if gridSearch:\n",
    "    parameters = {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  'n_neighbors' : [2,3,4,5,6,7,8,9,10],\n",
    "                  'weights' : ['uniform', 'distance']\n",
    "                 }\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(algorithm='auto', n_neighbors=2, weights='uniform')\n",
    "print(\"\\nCross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == knn_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:  {'n_estimators': 3}\n",
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = True\n",
    "if gridSearch:\n",
    "    parameters = {\n",
    "                  'n_estimators' : [2,3,4,5,6,7,8,9,10]\n",
    "                 }\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, oob_score=True, n_estimators=7)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == forest_clf.predict(X_test)) / len(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               5120      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 28 samples\n",
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 2.0450 - acc: 0.3000 - val_loss: 1.8479 - val_acc: 0.3929\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 1.2772 - acc: 0.9000 - val_loss: 1.5437 - val_acc: 0.4643\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7548 - acc: 1.0000 - val_loss: 1.3577 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4742 - acc: 1.0000 - val_loss: 1.2326 - val_acc: 0.5357\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3124 - acc: 1.0000 - val_loss: 1.1656 - val_acc: 0.5714\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2102 - acc: 1.0000 - val_loss: 1.1146 - val_acc: 0.5714\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1543 - acc: 1.0000 - val_loss: 1.0811 - val_acc: 0.5714\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1183 - acc: 1.0000 - val_loss: 1.0673 - val_acc: 0.5714\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0932 - acc: 1.0000 - val_loss: 1.0544 - val_acc: 0.5714\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0769 - acc: 1.0000 - val_loss: 1.0478 - val_acc: 0.5714\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0637 - acc: 1.0000 - val_loss: 1.0332 - val_acc: 0.5714\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0533 - acc: 1.0000 - val_loss: 1.0318 - val_acc: 0.6071\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 1.0000 - val_loss: 1.0287 - val_acc: 0.6071\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 1.0326 - val_acc: 0.6071\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0349 - acc: 1.0000 - val_loss: 1.0260 - val_acc: 0.6071\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0308 - acc: 1.0000 - val_loss: 1.0238 - val_acc: 0.6429\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 1.0305 - val_acc: 0.6429\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 1.0307 - val_acc: 0.6429\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 1.0364 - val_acc: 0.6429\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.0366 - val_acc: 0.6429\n",
      "28/28 [==============================] - 0s 62us/step\n",
      "Test loss: 1.036602258682251\n",
      "Test accuracy: 0.6428571343421936\n",
      "Test accuracy/loss ratio: 0.6201579525394881\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "batch_size = 1\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(Y_train)\n",
    "Y_train = binarizer.transform(Y_train)\n",
    "Y_test = binarizer.transform(Y_test)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy/loss ratio:', score[1] / score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_leds(leds):\n",
    "    leds_copy = leds.copy()\n",
    "    leds_copy = np.add(leds_copy, 1)\n",
    "    leds_copy = np.fmod(leds_copy, 2)\n",
    "    return leds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "def boost_by_inv_logic(preds, preds_inv, X):\n",
    "\n",
    "    l = len(X)\n",
    "    for indx in range(l):\n",
    "        pred = preds[indx]\n",
    "        pred_inv = preds_inv[indx]        \n",
    "        x = X[indx]\n",
    "    \n",
    "        for led_indx in range(len(LED_BLUE_PRINT)):\n",
    "            seg = LED_BLUE_PRINT[led_indx]\n",
    "            if np.min(seg - x) < 0:\n",
    "                pred[led_indx] = 0\n",
    "        \n",
    "        pred = np.divide(pred, np.add(pred_inv, 0.01))\n",
    "        preds[indx] = pred\n",
    "    \n",
    "    return softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsume_entity_affinity(led_label, affinity_calculation_result, pred):\n",
    "    entity_affinity = affinity_calculation_result['data'][led_label]['entityAffinity']\n",
    "    for indx in range(len(DIGITS)):\n",
    "        pred[indx] += entity_affinity[DIGITS[indx]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions_affinity(all_cases_features, affinity_calculation_result):\n",
    "    all_cases_features_values = all_cases_features.values\n",
    "    affinity_preds = []\n",
    "    for all_cases_features_value in all_cases_features_values:\n",
    "        \n",
    "        active_single_leds = []\n",
    "        for indx in range(len(all_cases_features_value)):\n",
    "            if all_cases_features_value[indx] == 0: continue\n",
    "            active_single_leds.append(LEDS_ARR[indx])\n",
    "        \n",
    "        pred = [1.0 for x in range(10)]\n",
    "        for indx in range(len(active_single_leds)):\n",
    "            led_label = active_single_leds[indx]\n",
    "            pred = subsume_entity_affinity(led_label, affinity_calculation_result, pred)\n",
    "            \n",
    "            out_indx = indx + 1\n",
    "            while out_indx < len(active_single_leds):\n",
    "                pred = subsume_entity_affinity(led_label + active_single_leds[out_indx], affinity_calculation_result, pred)\n",
    "                out_indx += 1\n",
    "            \n",
    "        pred = np.divide(pred, sum(pred) + 0.1)\n",
    "        affinity_preds.append(pred)\n",
    "        \n",
    "    return affinity_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions(all_cases_features):\n",
    "    all_cases_features_inv = inverse_leds(all_cases_features)\n",
    "    \n",
    "    preds_df = pd.DataFrame(columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    preds_df[\"TYPE\"] = None\n",
    "    \n",
    "    all_cases_features_,_,_,_,_,_ = process_data(x=all_cases_features, y=all_cases_features, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, scalar=scalar)\n",
    "    \n",
    "    all_cases_features_inv_,_,_,_,_,_ = process_data(x=all_cases_features_inv, y=all_cases_features_inv, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, scalar=scalar)\n",
    "    \n",
    "    preds = model.predict(all_cases_features_.copy())\n",
    "    preds_inv = model.predict(all_cases_features_inv_.copy())               \n",
    "    mlp_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    mlp_preds = np.multiply(mlp_preds, 100)\n",
    "    mlp_df = pd.DataFrame(mlp_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    mlp_df[\"TYPE\"] = \"MLP\"\n",
    "    preds_df = preds_df.append(mlp_df)\n",
    "    \n",
    "    \n",
    "    preds = forest_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = forest_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    rf_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    rf_preds = np.multiply(rf_preds, 100)\n",
    "    rf_df = pd.DataFrame(rf_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    rf_df[\"TYPE\"] = \"RF\";\n",
    "    preds_df = preds_df.append(rf_df)\n",
    "    \n",
    "    \n",
    "    preds = knn_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = knn_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    knn_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    knn_preds = np.multiply(knn_preds, 100)\n",
    "    knn_df = pd.DataFrame(knn_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    knn_df[\"TYPE\"] = \"KNN\"\n",
    "    preds_df = preds_df.append(knn_df)\n",
    "    \n",
    "    \n",
    "    preds = sgd_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = sgd_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    sgd_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    sgd_preds = np.multiply(sgd_preds, 100)\n",
    "    sgd_df = pd.DataFrame(sgd_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    sgd_df[\"TYPE\"] = \"SGD\"\n",
    "    preds_df = preds_df.append(sgd_df)\n",
    "    \n",
    "    \n",
    "    with open('affinity-session-data/Led7-777/AFFINITY_CALCULATION.txt', 'r') as myfile:\n",
    "        affinity_calculation_result = json.loads(myfile.read().replace('\\n', ''))\n",
    "        \n",
    "    preds = get_all_cases_predictions_affinity(all_cases_features.copy(), affinity_calculation_result)\n",
    "    preds_inv = get_all_cases_predictions_affinity(all_cases_features_inv.copy(), affinity_calculation_result)\n",
    "    \n",
    "    affinity_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    affinity_preds = np.multiply(affinity_preds, 100)\n",
    "    affinity_df = pd.DataFrame(affinity_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    affinity_df[\"TYPE\"] = \"AFFINITY\";\n",
    "    preds_df = preds_df.append(affinity_df)\n",
    "\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_features = load_data(ALL_CASES_INPUT_DATA)\n",
    "all_cases_predictions_df = get_all_cases_predictions(all_cases_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.864296e-21</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.287959e-18</td>\n",
       "      <td>6.973196e-21</td>\n",
       "      <td>2.025627e-09</td>\n",
       "      <td>1.598032e-20</td>\n",
       "      <td>4.508334e-21</td>\n",
       "      <td>3.826966e-19</td>\n",
       "      <td>3.661351e-21</td>\n",
       "      <td>4.348592e-21</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.499370e-28</td>\n",
       "      <td>2.499370e-28</td>\n",
       "      <td>8.943535e-25</td>\n",
       "      <td>9.247470e-28</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.057537e-27</td>\n",
       "      <td>3.085626e-28</td>\n",
       "      <td>2.499370e-28</td>\n",
       "      <td>2.712378e-28</td>\n",
       "      <td>3.175448e-28</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.799716e-20</td>\n",
       "      <td>4.243875e-20</td>\n",
       "      <td>4.243875e-20</td>\n",
       "      <td>4.243875e-20</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.662408e-19</td>\n",
       "      <td>4.658852e-20</td>\n",
       "      <td>4.243875e-20</td>\n",
       "      <td>4.266552e-20</td>\n",
       "      <td>5.509062e-20</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.222153e-30</td>\n",
       "      <td>1.222153e-30</td>\n",
       "      <td>1.222153e-30</td>\n",
       "      <td>1.222153e-30</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.987704e-30</td>\n",
       "      <td>1.287163e-30</td>\n",
       "      <td>1.222153e-30</td>\n",
       "      <td>1.253333e-30</td>\n",
       "      <td>1.450258e-30</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.828594e-05</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>9.999989e+01</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>1.453442e-05</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>7.279723e-06</td>\n",
       "      <td>6.431762e-06</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  5.864296e-21  1.000000e+02  3.287959e-18  6.973196e-21  2.025627e-09   \n",
       "1  2.499370e-28  2.499370e-28  8.943535e-25  9.247470e-28  1.000000e+02   \n",
       "2  5.799716e-20  4.243875e-20  4.243875e-20  4.243875e-20  1.000000e+02   \n",
       "3  1.222153e-30  1.222153e-30  1.222153e-30  1.222153e-30  1.000000e+02   \n",
       "4  2.828594e-05  6.431762e-06  9.999989e+01  6.431762e-06  6.431762e-06   \n",
       "\n",
       "              5             6             7             8             9 TYPE  \n",
       "0  1.598032e-20  4.508334e-21  3.826966e-19  3.661351e-21  4.348592e-21  MLP  \n",
       "1  1.057537e-27  3.085626e-28  2.499370e-28  2.712378e-28  3.175448e-28  MLP  \n",
       "2  1.662408e-19  4.658852e-20  4.243875e-20  4.266552e-20  5.509062e-20  MLP  \n",
       "3  1.987704e-30  1.287163e-30  1.222153e-30  1.253333e-30  1.450258e-30  MLP  \n",
       "4  6.431762e-06  1.453442e-05  6.431762e-06  7.279723e-06  6.431762e-06  MLP  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>2.574348</td>\n",
       "      <td>4.333474</td>\n",
       "      <td>75.071744</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>30.817069</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>24.493539</td>\n",
       "      <td>5.586174</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>30.358192</td>\n",
       "      <td>7.737979</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>83.289149</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>6.594476</td>\n",
       "      <td>1.264547</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>32.260062</td>\n",
       "      <td>7.526660</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "123   2.574348  2.574348  2.574348  2.574348  2.574348  2.574348  2.574348   \n",
       "124  30.817069  5.586174  5.586174  5.586174  5.586174  5.586174  5.586174   \n",
       "125   7.737979  7.737979  7.737979  7.737979  7.737979  7.737979  7.737979   \n",
       "126  83.289149  1.264547  1.264547  1.264547  1.264547  1.264547  1.264547   \n",
       "127   7.526660  7.526660  7.526660  7.526660  7.526660  7.526660  7.526660   \n",
       "\n",
       "            7          8          9      TYPE  \n",
       "123  2.574348   4.333474  75.071744  AFFINITY  \n",
       "124  5.586174  24.493539   5.586174  AFFINITY  \n",
       "125  7.737979  30.358192   7.737979  AFFINITY  \n",
       "126  1.264547   6.594476   1.264547  AFFINITY  \n",
       "127  7.526660  32.260062   7.526660  AFFINITY  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_predictions_df.to_csv(ALL_CASES_PREDICTIONS, sep=',', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
