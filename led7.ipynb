{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# LED PATTERNS for the digits 0 to 9\n",
    "LED_BLUE_PRINT = np.array([[1,1,1,1,1,1,0],\n",
    "                     [0,1,1,0,0,0,0],\n",
    "                     [1,1,0,1,1,0,1],\n",
    "                     [1,1,1,1,0,0,1],\n",
    "                     [0,0,1,0,0,1,1],\n",
    "                     [1,0,1,1,0,1,1],\n",
    "                     [1,0,1,1,1,1,1],\n",
    "                     [1,1,1,0,0,0,0],\n",
    "                     [1,1,1,1,1,1,1],\n",
    "                     [1,1,1,1,0,1,1]\n",
    "                    ])\n",
    "\n",
    "# All cases essential data files\n",
    "TRAIN_DATA_FILE = \"train_data.csv\"\n",
    "TEST_DATA_FILE = \"test_data.csv\"\n",
    "ALL_CASES_INPUT_DATA = \"all_cases_input_data.csv\"\n",
    "ALL_CASES_PREDICTIONS = \"all_cases_predictions.csv\"\n",
    "ALL_CASES_PREDICTIONS_COLUMS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "# LEDS and DIGITS arr to refer\n",
    "LEDS_ARR = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "DIGITS = [\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic data loading function\n",
    "def load_data(file=TRAIN_DATA_FILE, header=True):\n",
    "    csv_path = os.path.join(\"\", file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "# Drop DIGIT column and treat it as labels\n",
    "train_data = load_data(TRAIN_DATA_FILE)\n",
    "train_labels = train_data[\"DIGIT\"]\n",
    "train_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "test_data = load_data(TEST_DATA_FILE)\n",
    "test_labels = test_data[\"DIGIT\"]\n",
    "test_data.drop(\"DIGIT\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all cases input data\n",
    "all_cases_input_data = load_data(ALL_CASES_INPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the optimal dimensions using PCA\n",
    "# Return dimension where the minimum variance between the features drop to thres value\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_dims_variances(x, minDim, tol=None, thres=0.01):\n",
    "    dims = []\n",
    "    variances = []\n",
    "    optimum_dim = minDim\n",
    "    prev_min_variance = None\n",
    "    dim = minDim\n",
    "    \n",
    "    while(True):\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(x)\n",
    "        variance = np.array(pca.explained_variance_ratio_)\n",
    "        min_variance = variance.min()\n",
    "        \n",
    "        dims.append(dim)\n",
    "        variances.append(min_variance)\n",
    "        \n",
    "        if tol != None and prev_min_variance != None and min_variance + tol > prev_min_variance:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            if prev_min_variance != None and min_variance < thres:\n",
    "                break\n",
    "                \n",
    "        prev_min_variance = min_variance\n",
    "        optimum_dim = dim\n",
    "        dim = dim + 1\n",
    "\n",
    "    return dims, variances, optimum_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data processing routine\n",
    "\n",
    "def process_data(x, y, poly_features=None, pca=None, OPTIMUM_DIMENSION=None, imputer=None, scalar=None):\n",
    "    training_features = x.copy()\n",
    "    testing_features = y.copy()\n",
    "    \n",
    "    if imputer == None:\n",
    "        imputer = Imputer(strategy=\"median\")\n",
    "        imputer.fit(training_features)\n",
    "        \n",
    "    training_features = imputer.transform(training_features)\n",
    "    testing_features = imputer.transform(testing_features)\n",
    "    \n",
    "    if scalar == None:\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(training_features)\n",
    "        \n",
    "    training_features = scalar.transform(training_features)\n",
    "    testing_features = scalar.transform(testing_features)\n",
    "    \n",
    "    if poly_features == None:\n",
    "        poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        poly_features.fit(training_features)\n",
    "        \n",
    "    training_features = poly_features.transform(training_features)\n",
    "    testing_features = poly_features.transform(testing_features)\n",
    "\n",
    "    if OPTIMUM_DIMENSION == None:\n",
    "        dims, variances, OPTIMUM_DIMENSION = get_dims_variances(x=training_features, minDim=2, thres=0.005)\n",
    "        print(\"Optimum Dimensions: \", OPTIMUM_DIMENSION)\n",
    "        plt.plot(dims, variances)\n",
    "        plt.show()\n",
    "        dim_df = pd.DataFrame()\n",
    "        dim_df[\"DIM\"] = dims\n",
    "        dim_df[\"VAR\"] = variances\n",
    "\n",
    "    if pca == None:  \n",
    "        pca = PCA(random_state=42, n_components=OPTIMUM_DIMENSION)\n",
    "        pca.fit(training_features)\n",
    "        \n",
    "    training_features = pca.transform(training_features)\n",
    "    testing_features = pca.transform(testing_features)\n",
    "    \n",
    "    return training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Dimensions:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ac69940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar = process_data(x=train_data, y=test_data)\n",
    "\n",
    "training_labels = train_labels.values\n",
    "testing_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.35714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/Users/yogesh/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = False\n",
    "if gridSearch:\n",
    "    parameters = {\n",
    "                  'n_iter' : [2,3,4,5,6,7,8,9,10]\n",
    "                 }\n",
    "    clf = GridSearchCV(SGDClassifier(random_state=42), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, penalty=\"elasticnet\", loss='log', n_iter=3)\n",
    "cross_val_scores = cross_val_score(clone(sgd_clf), X_train, Y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_scores)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == sgd_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = False\n",
    "if gridSearch:\n",
    "    parameters = {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  'n_neighbors' : [2,3,4,5,6,7,8,9,10],\n",
    "                  'weights' : ['uniform', 'distance']\n",
    "                 }\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(algorithm='auto', n_neighbors=2, weights='uniform')\n",
    "print(\"\\nCross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == knn_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:  {'n_estimators': 3}\n",
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "gridSearch = True\n",
    "if gridSearch:\n",
    "    parameters = {\n",
    "                  'n_estimators' : [2,3,4,5,6,7,8,9,10]\n",
    "                 }\n",
    "    clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, oob_score=True, n_estimators=7)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == forest_clf.predict(X_test)) / len(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               5120      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 10,250\n",
      "Trainable params: 10,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 28 samples\n",
      "Epoch 1/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 2.0081 - acc: 0.4667 - val_loss: 2.0174 - val_acc: 0.2857\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 1.2770 - acc: 1.0000 - val_loss: 1.8667 - val_acc: 0.3571\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.8288 - acc: 1.0000 - val_loss: 1.7508 - val_acc: 0.3571\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5346 - acc: 1.0000 - val_loss: 1.7287 - val_acc: 0.3571\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3648 - acc: 1.0000 - val_loss: 1.7185 - val_acc: 0.3571\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2532 - acc: 1.0000 - val_loss: 1.7022 - val_acc: 0.3929\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1865 - acc: 1.0000 - val_loss: 1.6943 - val_acc: 0.3929\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1359 - acc: 1.0000 - val_loss: 1.6984 - val_acc: 0.3929\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 1.7120 - val_acc: 0.4286\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0828 - acc: 1.0000 - val_loss: 1.7231 - val_acc: 0.4286\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0679 - acc: 1.0000 - val_loss: 1.7314 - val_acc: 0.3929\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0563 - acc: 1.0000 - val_loss: 1.7379 - val_acc: 0.4286\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0472 - acc: 1.0000 - val_loss: 1.7514 - val_acc: 0.3929\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0407 - acc: 1.0000 - val_loss: 1.7635 - val_acc: 0.3929\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0351 - acc: 1.0000 - val_loss: 1.7744 - val_acc: 0.3929\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 1.7887 - val_acc: 0.3929\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 1.7967 - val_acc: 0.3929\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0240 - acc: 1.0000 - val_loss: 1.8078 - val_acc: 0.3929\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.8218 - val_acc: 0.3929\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 1.8301 - val_acc: 0.3929\n",
      "28/28 [==============================] - 0s 54us/step\n",
      "Test loss: 1.830138921737671\n",
      "Test accuracy: 0.3928571343421936\n",
      "Test accuracy/loss ratio: 0.21465973411962935\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "batch_size = 1\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0005),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(Y_train)\n",
    "Y_train = binarizer.transform(Y_train)\n",
    "Y_test = binarizer.transform(Y_test)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy/loss ratio:', score[1] / score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_leds(leds):\n",
    "    leds_copy = leds.copy()\n",
    "    leds_copy = np.add(leds_copy, 1)\n",
    "    leds_copy = np.fmod(leds_copy, 2)\n",
    "    return leds_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "def boost_by_inv_logic(preds, preds_inv, X):\n",
    "    l = len(X)\n",
    "    for indx in range(l):\n",
    "        pred = preds[indx]\n",
    "        pred_inv = preds_inv[indx]\n",
    "        x = X[indx]\n",
    "    \n",
    "        for led_indx in range(len(LED_BLUE_PRINT)):\n",
    "            seg = LED_BLUE_PRINT[led_indx]\n",
    "            if np.min(seg - x) < 0:\n",
    "                pred[led_indx] = 0\n",
    "        \n",
    "        #pred_inv = np.add(pred_inv, 0.01)\n",
    "        #preds[indx] = np.divide(pred, pred_inv)\n",
    "        preds[indx] = pred\n",
    "        \n",
    "    return softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsume_entity_affinity(led_label, affinity_calculation_result, pred):\n",
    "    entity_affinity = affinity_calculation_result['data'][led_label]['entityAffinity']\n",
    "    for indx in range(len(DIGITS)):\n",
    "        pred[indx] += entity_affinity[DIGITS[indx]]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions_affinity(all_cases_features, affinity_calculation_result):\n",
    "    all_cases_features_values = all_cases_features.values\n",
    "    affinity_preds = []\n",
    "    for all_cases_features_value in all_cases_features_values:\n",
    "        \n",
    "        active_single_leds = []\n",
    "        for indx in range(len(all_cases_features_value)):\n",
    "            if all_cases_features_value[indx] == 0: continue\n",
    "            active_single_leds.append(LEDS_ARR[indx])\n",
    "        \n",
    "        pred = [0.0 for x in range(10)]\n",
    "        for indx in range(len(active_single_leds)):\n",
    "            led_label = active_single_leds[indx]\n",
    "            pred = subsume_entity_affinity(led_label, affinity_calculation_result, pred)\n",
    "            \n",
    "            out_indx = indx + 1\n",
    "            while out_indx < len(active_single_leds):\n",
    "                pred = subsume_entity_affinity(led_label + active_single_leds[out_indx], affinity_calculation_result, pred)\n",
    "                out_indx += 1\n",
    "            \n",
    "        pred = np.divide(pred, sum(pred) + 0.1)\n",
    "        pred = np.multiply(pred, 100)\n",
    "        affinity_preds.append(pred)\n",
    "        \n",
    "    affinity_preds = np.array(affinity_preds)\n",
    "    affinity_df = pd.DataFrame(affinity_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    affinity_df[\"TYPE\"] = \"AFFINITY\";\n",
    "        \n",
    "    return affinity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions(all_cases_features):\n",
    "    all_cases_features_inv = inverse_leds(all_cases_features)\n",
    "    \n",
    "    preds_df = pd.DataFrame(columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    preds_df[\"TYPE\"] = None\n",
    "    \n",
    "    all_cases_features_,_,_,_,_,_,_ = process_data(x=all_cases_features, y=all_cases_features, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "    \n",
    "    all_cases_features_inv_,_,_,_,_,_,_ = process_data(x=all_cases_features_inv, y=all_cases_features_inv, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "    \n",
    "    preds = model.predict(all_cases_features_.copy())\n",
    "    preds_inv = model.predict(all_cases_features_inv_.copy())               \n",
    "    mlp_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    mlp_preds = np.multiply(mlp_preds, 100)\n",
    "    mlp_df = pd.DataFrame(mlp_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    mlp_df[\"TYPE\"] = \"MLP\"\n",
    "    preds_df = preds_df.append(mlp_df)\n",
    "    \n",
    "    \n",
    "    preds = forest_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = forest_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    rf_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    rf_preds = np.multiply(rf_preds, 100)\n",
    "    rf_df = pd.DataFrame(rf_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    rf_df[\"TYPE\"] = \"RF\";\n",
    "    preds_df = preds_df.append(rf_df)\n",
    "    \n",
    "    \n",
    "    preds = knn_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = knn_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    knn_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    knn_preds = np.multiply(knn_preds, 100)\n",
    "    knn_df = pd.DataFrame(knn_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    knn_df[\"TYPE\"] = \"KNN\"\n",
    "    preds_df = preds_df.append(knn_df)\n",
    "    \n",
    "    \n",
    "    preds = sgd_clf.predict_proba(all_cases_features_.copy())\n",
    "    preds_inv = sgd_clf.predict_proba(all_cases_features_inv_.copy()) \n",
    "    sgd_preds = boost_by_inv_logic(preds, preds_inv, all_cases_features.copy().values)\n",
    "    sgd_preds = np.multiply(sgd_preds, 100)\n",
    "    sgd_df = pd.DataFrame(sgd_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    sgd_df[\"TYPE\"] = \"SGD\"\n",
    "    preds_df = preds_df.append(sgd_df)\n",
    "    \n",
    "    \n",
    "    with open('affinity-session-data/Led7-777/AFFINITY_CALCULATION.txt', 'r') as myfile:\n",
    "        affinity_calculation_result = json.loads(myfile.read().replace('\\n', ''))\n",
    "        \n",
    "    affinity_df = get_all_cases_predictions_affinity(all_cases_features.copy(), affinity_calculation_result)\n",
    "    preds_df = preds_df.append(affinity_df)\n",
    "\n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_features = load_data(ALL_CASES_INPUT_DATA)\n",
    "all_cases_predictions_df = get_all_cases_predictions(all_cases_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.081184</td>\n",
       "      <td>11.848742</td>\n",
       "      <td>11.566585</td>\n",
       "      <td>9.064027</td>\n",
       "      <td>9.832640</td>\n",
       "      <td>9.050720</td>\n",
       "      <td>9.030071</td>\n",
       "      <td>9.098377</td>\n",
       "      <td>12.094970</td>\n",
       "      <td>9.332682</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.112054</td>\n",
       "      <td>9.112054</td>\n",
       "      <td>11.797271</td>\n",
       "      <td>9.303668</td>\n",
       "      <td>14.418475</td>\n",
       "      <td>9.181708</td>\n",
       "      <td>9.207438</td>\n",
       "      <td>9.112054</td>\n",
       "      <td>9.384938</td>\n",
       "      <td>9.370337</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.358452</td>\n",
       "      <td>9.201366</td>\n",
       "      <td>9.201366</td>\n",
       "      <td>9.201366</td>\n",
       "      <td>16.180779</td>\n",
       "      <td>9.319937</td>\n",
       "      <td>9.301088</td>\n",
       "      <td>9.201366</td>\n",
       "      <td>9.692392</td>\n",
       "      <td>9.341880</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.668295</td>\n",
       "      <td>8.668295</td>\n",
       "      <td>8.668295</td>\n",
       "      <td>8.668295</td>\n",
       "      <td>21.848528</td>\n",
       "      <td>8.707028</td>\n",
       "      <td>8.699068</td>\n",
       "      <td>8.668295</td>\n",
       "      <td>8.694063</td>\n",
       "      <td>8.709834</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.628125</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>13.880207</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>9.571830</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>9.622121</td>\n",
       "      <td>9.549620</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2         3          4         5         6  \\\n",
       "0  9.081184  11.848742  11.566585  9.064027   9.832640  9.050720  9.030071   \n",
       "1  9.112054   9.112054  11.797271  9.303668  14.418475  9.181708  9.207438   \n",
       "2  9.358452   9.201366   9.201366  9.201366  16.180779  9.319937  9.301088   \n",
       "3  8.668295   8.668295   8.668295  8.668295  21.848528  8.707028  8.699068   \n",
       "4  9.628125   9.549620  13.880207  9.549620   9.549620  9.549620  9.571830   \n",
       "\n",
       "          7          8         9 TYPE  \n",
       "0  9.098377  12.094970  9.332682  MLP  \n",
       "1  9.112054   9.384938  9.370337  MLP  \n",
       "2  9.201366   9.692392  9.341880  MLP  \n",
       "3  8.668295   8.694063  8.709834  MLP  \n",
       "4  9.549620   9.622121  9.549620  MLP  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12.030609</td>\n",
       "      <td>2.723732</td>\n",
       "      <td>10.007809</td>\n",
       "      <td>11.155872</td>\n",
       "      <td>9.298306</td>\n",
       "      <td>12.064893</td>\n",
       "      <td>9.244974</td>\n",
       "      <td>5.307467</td>\n",
       "      <td>13.675800</td>\n",
       "      <td>14.485777</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>15.817122</td>\n",
       "      <td>4.818602</td>\n",
       "      <td>12.107172</td>\n",
       "      <td>8.373888</td>\n",
       "      <td>4.592605</td>\n",
       "      <td>7.299903</td>\n",
       "      <td>12.094505</td>\n",
       "      <td>8.147891</td>\n",
       "      <td>17.131105</td>\n",
       "      <td>9.610539</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>13.225714</td>\n",
       "      <td>4.150952</td>\n",
       "      <td>12.573333</td>\n",
       "      <td>9.627619</td>\n",
       "      <td>6.332857</td>\n",
       "      <td>9.439048</td>\n",
       "      <td>11.830952</td>\n",
       "      <td>6.064286</td>\n",
       "      <td>16.245238</td>\n",
       "      <td>10.505238</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>15.740326</td>\n",
       "      <td>3.483300</td>\n",
       "      <td>11.446558</td>\n",
       "      <td>8.040400</td>\n",
       "      <td>6.605651</td>\n",
       "      <td>8.457538</td>\n",
       "      <td>12.138456</td>\n",
       "      <td>6.054228</td>\n",
       "      <td>16.609366</td>\n",
       "      <td>11.419415</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>13.627094</td>\n",
       "      <td>3.144274</td>\n",
       "      <td>11.864600</td>\n",
       "      <td>9.141039</td>\n",
       "      <td>7.666044</td>\n",
       "      <td>10.124250</td>\n",
       "      <td>11.920315</td>\n",
       "      <td>4.739269</td>\n",
       "      <td>15.886015</td>\n",
       "      <td>11.883529</td>\n",
       "      <td>AFFINITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1          2          3         4          5  \\\n",
       "123  12.030609  2.723732  10.007809  11.155872  9.298306  12.064893   \n",
       "124  15.817122  4.818602  12.107172   8.373888  4.592605   7.299903   \n",
       "125  13.225714  4.150952  12.573333   9.627619  6.332857   9.439048   \n",
       "126  15.740326  3.483300  11.446558   8.040400  6.605651   8.457538   \n",
       "127  13.627094  3.144274  11.864600   9.141039  7.666044  10.124250   \n",
       "\n",
       "             6         7          8          9      TYPE  \n",
       "123   9.244974  5.307467  13.675800  14.485777  AFFINITY  \n",
       "124  12.094505  8.147891  17.131105   9.610539  AFFINITY  \n",
       "125  11.830952  6.064286  16.245238  10.505238  AFFINITY  \n",
       "126  12.138456  6.054228  16.609366  11.419415  AFFINITY  \n",
       "127  11.920315  4.739269  15.886015  11.883529  AFFINITY  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_predictions_df.to_csv(ALL_CASES_PREDICTIONS, sep=',', index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
