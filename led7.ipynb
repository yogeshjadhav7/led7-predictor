{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "TRAIN_DATA_FILE = \"train_data.csv\"\n",
    "TEST_DATA_FILE = \"test_data.csv\"\n",
    "ALL_CASES_INPUT_DATA = \"all_cases_input_data.csv\"\n",
    "ALL_CASES_PREDICTIONS = \"all_cases_predictions.csv\"\n",
    "ALL_CASES_PREDICTIONS_COLUMS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "def load_data(file=TRAIN_DATA_FILE, header=True):\n",
    "    csv_path = os.path.join(\"\", file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(TRAIN_DATA_FILE)\n",
    "train_labels = train_data[\"DIGIT\"]\n",
    "train_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "test_data = load_data(TEST_DATA_FILE)\n",
    "test_labels = test_data[\"DIGIT\"]\n",
    "test_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "all_cases_input_data = load_data(ALL_CASES_INPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_dims_variances(x, minDim, tol=None, thres=0.01):\n",
    "    dims = []\n",
    "    variances = []\n",
    "    optimum_dim = minDim\n",
    "    prev_min_variance = None\n",
    "    dim = minDim\n",
    "    \n",
    "    while(True):\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(x)\n",
    "        variance = np.array(pca.explained_variance_ratio_)\n",
    "        min_variance = variance.min()\n",
    "        \n",
    "        dims.append(dim)\n",
    "        variances.append(min_variance)\n",
    "        \n",
    "        if tol != None and prev_min_variance != None and min_variance + tol > prev_min_variance:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            if prev_min_variance != None and min_variance < thres:\n",
    "                break\n",
    "                \n",
    "        prev_min_variance = min_variance\n",
    "        optimum_dim = dim\n",
    "        dim = dim + 1\n",
    "\n",
    "    return dims, variances, optimum_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def process_data(x, y, poly_features=None, pca=None, OPTIMUM_DIMENSION=None, imputer=None, scalar=None):\n",
    "    training_features = x.copy()\n",
    "    testing_features = y.copy()\n",
    "    \n",
    "    if imputer == None:\n",
    "        imputer = Imputer(strategy=\"median\")\n",
    "        imputer.fit(training_features)\n",
    "        \n",
    "    training_features = imputer.transform(training_features)\n",
    "    testing_features = imputer.transform(testing_features)\n",
    "    \n",
    "    if scalar == None:\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(training_features)\n",
    "        \n",
    "    training_features = scalar.transform(training_features)\n",
    "    testing_features = scalar.transform(testing_features)\n",
    "    \n",
    "    if poly_features == None:\n",
    "        poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        poly_features.fit(training_features)\n",
    "        \n",
    "    training_features = poly_features.transform(training_features)\n",
    "    testing_features = poly_features.transform(testing_features)\n",
    "\n",
    "    if OPTIMUM_DIMENSION == None:\n",
    "        dims, variances, OPTIMUM_DIMENSION = get_dims_variances(x=training_features, minDim=2, thres=0.005)\n",
    "        print(\"Optimum Dimensions: \", OPTIMUM_DIMENSION)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(dims, variances)\n",
    "        plt.show()\n",
    "        dim_df = pd.DataFrame()\n",
    "        dim_df[\"DIM\"] = dims\n",
    "        dim_df[\"VAR\"] = variances\n",
    "        print(dim_df)\n",
    "\n",
    "    if pca == None:  \n",
    "        pca = PCA(random_state=42, n_components=OPTIMUM_DIMENSION)\n",
    "        pca.fit(training_features)\n",
    "        \n",
    "    training_features = pca.transform(training_features)\n",
    "    testing_features = pca.transform(testing_features)\n",
    "    \n",
    "    return training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Dimensions:  9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113346f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DIM           VAR\n",
      "0    2  2.007405e-01\n",
      "1    3  1.802780e-01\n",
      "2    4  7.318341e-02\n",
      "3    5  6.323851e-02\n",
      "4    6  4.993933e-02\n",
      "5    7  3.180211e-02\n",
      "6    8  2.395129e-02\n",
      "7    9  9.933956e-03\n",
      "8   10  4.527608e-32\n"
     ]
    }
   ],
   "source": [
    "training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar = process_data(x=train_data, y=test_data)\n",
    "\n",
    "training_labels = train_labels.values\n",
    "testing_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.35\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, penalty=\"elasticnet\", loss='log')\n",
    "cross_val_scores = cross_val_score(clone(sgd_clf), X_train, Y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_scores)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == sgd_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:  {'algorithm': 'auto', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "parameters = {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'n_neighbors' : [2,3,4,5,6,7,8,9,10],\n",
    "              'weights' : ['uniform', 'distance']\n",
    "             }\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(algorithm='auto', n_neighbors=2, weights='uniform')\n",
    "print(\"\\nCross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [1. 1. 1.]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.35\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, oob_score=True, n_estimators=5)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == forest_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               2560      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30 samples, validate on 20 samples\n",
      "Epoch 1/15\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 3.1809 - acc: 0.0000e+00 - val_loss: 2.2748 - val_acc: 0.1000\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 2.6955 - acc: 0.1000 - val_loss: 2.1534 - val_acc: 0.1500\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.9532 - acc: 0.3667 - val_loss: 2.0480 - val_acc: 0.3000\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - 0s 993us/step - loss: 2.0107 - acc: 0.2000 - val_loss: 1.9613 - val_acc: 0.3500\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.5330 - acc: 0.5000 - val_loss: 1.9064 - val_acc: 0.3500\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.4705 - acc: 0.5667 - val_loss: 1.8754 - val_acc: 0.3500\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.4637 - acc: 0.4333 - val_loss: 1.8631 - val_acc: 0.3500\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0166 - acc: 0.8000 - val_loss: 1.8586 - val_acc: 0.3500\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0566 - acc: 0.7333 - val_loss: 1.8394 - val_acc: 0.4000\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.9966 - acc: 0.7333 - val_loss: 1.8363 - val_acc: 0.4000\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6886 - acc: 0.9667 - val_loss: 1.8230 - val_acc: 0.4000\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.8107 - acc: 0.8667 - val_loss: 1.8025 - val_acc: 0.4500\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 1.0043 - acc: 0.7000 - val_loss: 1.8061 - val_acc: 0.4500\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.4696 - acc: 1.0000 - val_loss: 1.8072 - val_acc: 0.4500\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.6226 - acc: 0.9333 - val_loss: 1.8123 - val_acc: 0.4500\n",
      "20/20 [==============================] - 0s 142us/step\n",
      "Test loss: 1.8122583627700806\n",
      "Test accuracy: 0.44999998807907104\n",
      "Test accuracy/loss ratio: 0.24830895932036712\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "batch_size = 3\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(Y_train)\n",
    "Y_train = binarizer.transform(Y_train)\n",
    "Y_test = binarizer.transform(Y_test)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy/loss ratio:', score[1] / score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02855825 0.01154422 0.16100365 0.04070703 0.67782676 0.0106171\n",
      "  0.01573212 0.01646328 0.02018954 0.01735801]]\n",
      "[[0.  0.  0.  0.  0.8 0.  0.  0.  0.  0.2]]\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "x = [[0,0,0,0,0,1,1]]\n",
    "x_,_,_,_,_,_,_ = process_data(x=x, y=x, poly_features=poly_features, pca=pca, OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "print(model.predict(x_.copy()))\n",
    "print(forest_clf.predict_proba(x_.copy()))\n",
    "print(knn_clf.predict_proba(x_.copy()))\n",
    "print(sgd_clf.predict(x_.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00909319 0.07442424 0.71788096 0.02560439 0.02786103 0.02376629\n",
      "  0.0212886  0.06476229 0.01873636 0.01658268]]\n",
      "[[0.2 0.  0.2 0.  0.  0.  0.  0.  0.  0.6]]\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "x = [[0,1,0,1,0,0,0]]\n",
    "x_,_,_,_,_,_,_ = process_data(x=x, y=x, poly_features=poly_features, pca=pca, OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "print(model.predict(x_.copy()))\n",
    "print(forest_clf.predict_proba(x_.copy()))\n",
    "print(knn_clf.predict_proba(x_.copy()))\n",
    "print(sgd_clf.predict(x_.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions(all_cases_features):\n",
    "    preds_df = pd.DataFrame(columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    preds_df[\"TYPE\"] = None\n",
    "    \n",
    "    all_cases_features,_,_,_,_,_,_ = process_data(x=all_cases_features, y=all_cases_features, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "    \n",
    "    mlp_preds = model.predict(all_cases_features.copy())\n",
    "    mlp_preds = np.multiply(mlp_preds, 100)\n",
    "    mlp_df = pd.DataFrame(mlp_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    mlp_df[\"TYPE\"] = \"MLP\"\n",
    "    preds_df = preds_df.append(mlp_df)\n",
    "    \n",
    "    rf_preds = forest_clf.predict_proba(all_cases_features.copy())\n",
    "    rf_preds = np.multiply(rf_preds, 100)\n",
    "    rf_df = pd.DataFrame(rf_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    rf_df[\"TYPE\"] = \"RF\";\n",
    "    preds_df = preds_df.append(rf_df)\n",
    "    \n",
    "    knn_preds = knn_clf.predict_proba(all_cases_features.copy())\n",
    "    knn_preds = np.multiply(knn_preds, 100)\n",
    "    knn_df = pd.DataFrame(knn_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    knn_df[\"TYPE\"] = \"KNN\"\n",
    "    preds_df = preds_df.append(knn_df)\n",
    "    \n",
    "    sgd_preds = sgd_clf.predict_proba(all_cases_features.copy())\n",
    "    sgd_preds = np.multiply(sgd_preds, 100)\n",
    "    sgd_df = pd.DataFrame(sgd_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    sgd_df[\"TYPE\"] = \"SGD\"\n",
    "    preds_df = preds_df.append(sgd_df)\n",
    "    \n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_features = load_data(ALL_CASES_INPUT_DATA)\n",
    "all_cases_predictions_df = get_all_cases_predictions(all_cases_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937354</td>\n",
       "      <td>21.274891</td>\n",
       "      <td>30.506653</td>\n",
       "      <td>3.711892</td>\n",
       "      <td>21.802532</td>\n",
       "      <td>2.402566</td>\n",
       "      <td>1.984207</td>\n",
       "      <td>5.400710</td>\n",
       "      <td>9.636287</td>\n",
       "      <td>2.342908</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.781345</td>\n",
       "      <td>3.509519</td>\n",
       "      <td>44.956905</td>\n",
       "      <td>4.011583</td>\n",
       "      <td>31.728107</td>\n",
       "      <td>1.845700</td>\n",
       "      <td>1.487259</td>\n",
       "      <td>2.777092</td>\n",
       "      <td>3.804633</td>\n",
       "      <td>2.097848</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.372600</td>\n",
       "      <td>6.181278</td>\n",
       "      <td>17.321737</td>\n",
       "      <td>6.730519</td>\n",
       "      <td>50.803001</td>\n",
       "      <td>1.653923</td>\n",
       "      <td>2.755217</td>\n",
       "      <td>3.083224</td>\n",
       "      <td>5.930054</td>\n",
       "      <td>3.168456</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.855825</td>\n",
       "      <td>1.154422</td>\n",
       "      <td>16.100363</td>\n",
       "      <td>4.070703</td>\n",
       "      <td>67.782677</td>\n",
       "      <td>1.061710</td>\n",
       "      <td>1.573211</td>\n",
       "      <td>1.646328</td>\n",
       "      <td>2.018954</td>\n",
       "      <td>1.735800</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.279252</td>\n",
       "      <td>5.779332</td>\n",
       "      <td>71.463989</td>\n",
       "      <td>2.168461</td>\n",
       "      <td>5.687382</td>\n",
       "      <td>1.377366</td>\n",
       "      <td>0.528813</td>\n",
       "      <td>5.861566</td>\n",
       "      <td>1.349989</td>\n",
       "      <td>5.503853</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2         3          4         5         6  \\\n",
       "0  0.937354  21.274891  30.506653  3.711892  21.802532  2.402566  1.984207   \n",
       "1  3.781345   3.509519  44.956905  4.011583  31.728107  1.845700  1.487259   \n",
       "2  2.372600   6.181278  17.321737  6.730519  50.803001  1.653923  2.755217   \n",
       "3  2.855825   1.154422  16.100363  4.070703  67.782677  1.061710  1.573211   \n",
       "4  0.279252   5.779332  71.463989  2.168461   5.687382  1.377366  0.528813   \n",
       "\n",
       "          7         8         9 TYPE  \n",
       "0  5.400710  9.636287  2.342908  MLP  \n",
       "1  2.777092  3.804633  2.097848  MLP  \n",
       "2  3.083224  5.930054  3.168456  MLP  \n",
       "3  1.646328  2.018954  1.735800  MLP  \n",
       "4  5.861566  1.349989  5.503853  MLP  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.389167e-40</td>\n",
       "      <td>9.308880e-05</td>\n",
       "      <td>1.916500e-64</td>\n",
       "      <td>3.625981e-47</td>\n",
       "      <td>6.876645e-24</td>\n",
       "      <td>1.111708e-12</td>\n",
       "      <td>4.327368e-68</td>\n",
       "      <td>1.582514e-34</td>\n",
       "      <td>1.470958e-58</td>\n",
       "      <td>9.999991e+01</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.570687e-75</td>\n",
       "      <td>5.699023e-76</td>\n",
       "      <td>1.110397e-32</td>\n",
       "      <td>7.362085e-23</td>\n",
       "      <td>2.637263e-34</td>\n",
       "      <td>4.501465e-59</td>\n",
       "      <td>2.668580e-06</td>\n",
       "      <td>8.656109e-41</td>\n",
       "      <td>1.445087e-40</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.459155e-34</td>\n",
       "      <td>4.763749e-33</td>\n",
       "      <td>4.196372e-15</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.160484e-15</td>\n",
       "      <td>9.814836e-20</td>\n",
       "      <td>5.124223e-45</td>\n",
       "      <td>8.720344e-25</td>\n",
       "      <td>3.985954e-08</td>\n",
       "      <td>1.570462e-49</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.761706e-49</td>\n",
       "      <td>5.516681e-71</td>\n",
       "      <td>7.779503e-29</td>\n",
       "      <td>2.115436e-33</td>\n",
       "      <td>3.671498e-33</td>\n",
       "      <td>1.506023e-50</td>\n",
       "      <td>4.095548e-06</td>\n",
       "      <td>4.250641e-15</td>\n",
       "      <td>1.043459e-40</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.744366e-40</td>\n",
       "      <td>4.993504e-11</td>\n",
       "      <td>1.751118e-34</td>\n",
       "      <td>2.514804e-25</td>\n",
       "      <td>7.630724e-28</td>\n",
       "      <td>1.032131e-22</td>\n",
       "      <td>9.535684e-46</td>\n",
       "      <td>1.990829e-11</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.634272e-33</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4  \\\n",
       "123  1.389167e-40  9.308880e-05  1.916500e-64  3.625981e-47  6.876645e-24   \n",
       "124  1.000000e+02  6.570687e-75  5.699023e-76  1.110397e-32  7.362085e-23   \n",
       "125  1.459155e-34  4.763749e-33  4.196372e-15  1.000000e+02  2.160484e-15   \n",
       "126  1.000000e+02  2.761706e-49  5.516681e-71  7.779503e-29  2.115436e-33   \n",
       "127  1.744366e-40  4.993504e-11  1.751118e-34  2.514804e-25  7.630724e-28   \n",
       "\n",
       "                5             6             7             8             9 TYPE  \n",
       "123  1.111708e-12  4.327368e-68  1.582514e-34  1.470958e-58  9.999991e+01  SGD  \n",
       "124  2.637263e-34  4.501465e-59  2.668580e-06  8.656109e-41  1.445087e-40  SGD  \n",
       "125  9.814836e-20  5.124223e-45  8.720344e-25  3.985954e-08  1.570462e-49  SGD  \n",
       "126  3.671498e-33  1.506023e-50  4.095548e-06  4.250641e-15  1.043459e-40  SGD  \n",
       "127  1.032131e-22  9.535684e-46  1.990829e-11  1.000000e+02  1.634272e-33  SGD  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
