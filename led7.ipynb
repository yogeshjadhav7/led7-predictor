{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "TRAIN_DATA_FILE = \"train_data.csv\"\n",
    "TEST_DATA_FILE = \"test_data.csv\"\n",
    "ALL_CASES_INPUT_DATA = \"all_cases_input_data.csv\"\n",
    "ALL_CASES_PREDICTIONS = \"all_cases_predictions.csv\"\n",
    "ALL_CASES_PREDICTIONS_COLUMS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "def load_data(file=TRAIN_DATA_FILE, header=True):\n",
    "    csv_path = os.path.join(\"\", file)\n",
    "    if header:\n",
    "        return pd.read_csv(csv_path)\n",
    "    else:\n",
    "        return pd.read_csv(csv_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(TRAIN_DATA_FILE)\n",
    "train_labels = train_data[\"DIGIT\"]\n",
    "train_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "test_data = load_data(TEST_DATA_FILE)\n",
    "test_labels = test_data[\"DIGIT\"]\n",
    "test_data.drop(\"DIGIT\", axis=1, inplace=True)\n",
    "\n",
    "all_cases_input_data = load_data(ALL_CASES_INPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def get_dims_variances(x, minDim, tol=None, thres=0.01):\n",
    "    dims = []\n",
    "    variances = []\n",
    "    optimum_dim = minDim\n",
    "    prev_min_variance = None\n",
    "    dim = minDim\n",
    "    \n",
    "    while(True):\n",
    "        pca = PCA(n_components=dim)\n",
    "        pca.fit(x)\n",
    "        variance = np.array(pca.explained_variance_ratio_)\n",
    "        min_variance = variance.min()\n",
    "        \n",
    "        dims.append(dim)\n",
    "        variances.append(min_variance)\n",
    "        \n",
    "        if tol != None and prev_min_variance != None and min_variance + tol > prev_min_variance:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            if prev_min_variance != None and min_variance < thres:\n",
    "                break\n",
    "                \n",
    "        prev_min_variance = min_variance\n",
    "        optimum_dim = dim\n",
    "        dim = dim + 1\n",
    "\n",
    "    return dims, variances, optimum_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def process_data(x, y, poly_features=None, pca=None, OPTIMUM_DIMENSION=None, imputer=None, scalar=None):\n",
    "    training_features = x.copy()\n",
    "    testing_features = y.copy()\n",
    "    \n",
    "    if imputer == None:\n",
    "        imputer = Imputer(strategy=\"median\")\n",
    "        imputer.fit(training_features)\n",
    "        \n",
    "    training_features = imputer.transform(training_features)\n",
    "    testing_features = imputer.transform(testing_features)\n",
    "    \n",
    "    if scalar == None:\n",
    "        scalar = StandardScaler()\n",
    "        scalar.fit(training_features)\n",
    "        \n",
    "    training_features = scalar.transform(training_features)\n",
    "    testing_features = scalar.transform(testing_features)\n",
    "    \n",
    "    if poly_features == None:\n",
    "        poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        poly_features.fit(training_features)\n",
    "        \n",
    "    training_features = poly_features.transform(training_features)\n",
    "    testing_features = poly_features.transform(testing_features)\n",
    "\n",
    "    if OPTIMUM_DIMENSION == None:\n",
    "        dims, variances, OPTIMUM_DIMENSION = get_dims_variances(x=training_features, minDim=2, thres=0.005)\n",
    "        print(\"Optimum Dimensions: \", OPTIMUM_DIMENSION)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(dims, variances)\n",
    "        plt.show()\n",
    "        dim_df = pd.DataFrame()\n",
    "        dim_df[\"DIM\"] = dims\n",
    "        dim_df[\"VAR\"] = variances\n",
    "        print(dim_df)\n",
    "\n",
    "    if pca == None:  \n",
    "        pca = PCA(random_state=42, n_components=OPTIMUM_DIMENSION)\n",
    "        pca.fit(training_features)\n",
    "        \n",
    "    training_features = pca.transform(training_features)\n",
    "    testing_features = pca.transform(testing_features)\n",
    "    \n",
    "    return training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Dimensions:  22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b6bb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DIM       VAR\n",
      "0     2  0.104665\n",
      "1     3  0.086615\n",
      "2     4  0.076949\n",
      "3     5  0.066440\n",
      "4     6  0.064644\n",
      "5     7  0.058735\n",
      "6     8  0.050645\n",
      "7     9  0.047481\n",
      "8    10  0.040086\n",
      "9    11  0.037579\n",
      "10   12  0.032728\n",
      "11   13  0.029205\n",
      "12   14  0.027545\n",
      "13   15  0.024633\n",
      "14   16  0.019721\n",
      "15   17  0.016955\n",
      "16   18  0.015201\n",
      "17   19  0.011630\n",
      "18   20  0.007355\n",
      "19   21  0.006022\n",
      "20   22  0.005319\n",
      "21   23  0.002975\n"
     ]
    }
   ],
   "source": [
    "training_features, testing_features, poly_features, pca, OPTIMUM_DIMENSION, imputer, scalar = process_data(x=train_data, y=test_data)\n",
    "\n",
    "training_labels = train_labels.values\n",
    "testing_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [0.66666667 0.9        0.8       ]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, penalty=\"elasticnet\", loss='log')\n",
    "cross_val_scores = cross_val_score(clone(sgd_clf), X_train, Y_train, cv=3, scoring=\"accuracy\")\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_scores)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == sgd_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params:  {'algorithm': 'auto', 'n_neighbors': 2, 'weights': 'uniform'}\n",
      "\n",
      "Cross Val Scores on training set\n",
      " [0.72222222 0.6        0.8       ]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "parameters = {'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'n_neighbors' : [2,3,4,5,6,7,8,9,10],\n",
    "              'weights' : ['uniform', 'distance']\n",
    "             }\n",
    "clf = GridSearchCV(KNeighborsClassifier(), parameters)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"\\nBest params: \", clf.best_params_)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(algorithm='auto', n_neighbors=2, weights='uniform')\n",
    "print(\"\\nCross Val Scores on training set\\n\", cross_val_score(clone(knn_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "knn_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores on training set\n",
      " [0.22222222 0.2        0.4       ]\n",
      "\n",
      "\n",
      "Accuracy on testing data set\n",
      " 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42, oob_score=True, n_estimators=5)\n",
    "print(\"Cross Val Scores on training set\\n\", cross_val_score(clone(forest_clf), X_train, Y_train, cv=3, scoring=\"accuracy\"))\n",
    "\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "print(\"\\n\\nAccuracy on testing data set\\n\", sum(Y_test == forest_clf.predict(X_test)) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               5888      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 8,458\n",
      "Trainable params: 8,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 38 samples, validate on 28 samples\n",
      "Epoch 1/15\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 2.4395 - acc: 0.0526 - val_loss: 2.0074 - val_acc: 0.2500\n",
      "Epoch 2/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.9394 - acc: 0.3158 - val_loss: 1.6946 - val_acc: 0.6071\n",
      "Epoch 3/15\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6654 - acc: 0.5000 - val_loss: 1.4147 - val_acc: 0.8571\n",
      "Epoch 4/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.3913 - acc: 0.6842 - val_loss: 1.1841 - val_acc: 0.8929\n",
      "Epoch 5/15\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1802 - acc: 0.8158 - val_loss: 0.9851 - val_acc: 0.9286\n",
      "Epoch 6/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.9872 - acc: 0.8947 - val_loss: 0.8222 - val_acc: 0.9286\n",
      "Epoch 7/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.8601 - acc: 0.8947 - val_loss: 0.6901 - val_acc: 0.9286\n",
      "Epoch 8/15\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7144 - acc: 0.9474 - val_loss: 0.5823 - val_acc: 0.9286\n",
      "Epoch 9/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6197 - acc: 0.9737 - val_loss: 0.4957 - val_acc: 0.9286\n",
      "Epoch 10/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5400 - acc: 0.9211 - val_loss: 0.4297 - val_acc: 0.9286\n",
      "Epoch 11/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5192 - acc: 0.8947 - val_loss: 0.3735 - val_acc: 0.9286\n",
      "Epoch 12/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4704 - acc: 0.9211 - val_loss: 0.3260 - val_acc: 0.9286\n",
      "Epoch 13/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3928 - acc: 0.9737 - val_loss: 0.2870 - val_acc: 0.9286\n",
      "Epoch 14/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3829 - acc: 0.9474 - val_loss: 0.2523 - val_acc: 0.9643\n",
      "Epoch 15/15\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3078 - acc: 0.9474 - val_loss: 0.2293 - val_acc: 0.9286\n",
      "28/28 [==============================] - 0s 54us/step\n",
      "Test loss: 0.22933180630207062\n",
      "Test accuracy: 0.9285714030265808\n",
      "Test accuracy/loss ratio: 4.04903017160859\n"
     ]
    }
   ],
   "source": [
    "# MLP Classifier\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X_train = training_features\n",
    "Y_train = training_labels\n",
    "X_test = testing_features\n",
    "Y_test = testing_labels\n",
    "batch_size = 3\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(Y_train)\n",
    "Y_train = binarizer.transform(Y_train)\n",
    "Y_test = binarizer.transform(Y_test)\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy/loss ratio:', score[1] / score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02388783 0.00991701 0.00654111 0.00775802 0.90135974 0.03303823\n",
      "  0.00259724 0.00644441 0.00484932 0.00360716]]\n",
      "[[0.2 0.  0.  0.  0.6 0.  0.2 0.  0.  0. ]]\n",
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "x = [[0,0,0,0,0,1,1]]\n",
    "x_,_,_,_,_,_,_ = process_data(x=x, y=x, poly_features=poly_features, pca=pca, OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "print(model.predict(x_.copy()))\n",
    "print(forest_clf.predict_proba(x_.copy()))\n",
    "print(knn_clf.predict_proba(x_.copy()))\n",
    "print(sgd_clf.predict(x_.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.518829   0.01169285 0.08506533 0.05207281 0.04648864 0.0260013\n",
      "  0.10674343 0.03346601 0.08589728 0.03374337]]\n",
      "[[0.4 0.  0.  0.  0.  0.2 0.  0.  0.2 0.2]]\n",
      "[[0.5 0.  0.  0.5 0.  0.  0.  0.  0.  0. ]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "x = [[0,1,0,1,1,1,0]]\n",
    "x_,_,_,_,_,_,_ = process_data(x=x, y=x, poly_features=poly_features, pca=pca, OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "print(model.predict(x_.copy()))\n",
    "print(forest_clf.predict_proba(x_.copy()))\n",
    "print(knn_clf.predict_proba(x_.copy()))\n",
    "print(sgd_clf.predict(x_.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cases_predictions(all_cases_features):\n",
    "    preds_df = pd.DataFrame(columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    preds_df[\"TYPE\"] = None\n",
    "    \n",
    "    all_cases_features,_,_,_,_,_,_ = process_data(x=all_cases_features, y=all_cases_features, \n",
    "                                              poly_features=poly_features, pca=pca, \n",
    "                                              OPTIMUM_DIMENSION=OPTIMUM_DIMENSION, imputer=imputer, scalar=scalar)\n",
    "    \n",
    "    mlp_preds = model.predict(all_cases_features.copy())\n",
    "    mlp_preds = np.multiply(mlp_preds, 100)\n",
    "    mlp_df = pd.DataFrame(mlp_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    mlp_df[\"TYPE\"] = \"MLP\"\n",
    "    preds_df = preds_df.append(mlp_df)\n",
    "    \n",
    "    rf_preds = forest_clf.predict_proba(all_cases_features.copy())\n",
    "    rf_preds = np.multiply(rf_preds, 100)\n",
    "    rf_df = pd.DataFrame(rf_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    rf_df[\"TYPE\"] = \"RF\";\n",
    "    preds_df = preds_df.append(rf_df)\n",
    "    \n",
    "    knn_preds = knn_clf.predict_proba(all_cases_features.copy())\n",
    "    knn_preds = np.multiply(knn_preds, 100)\n",
    "    knn_df = pd.DataFrame(knn_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    knn_df[\"TYPE\"] = \"KNN\"\n",
    "    preds_df = preds_df.append(knn_df)\n",
    "    \n",
    "    sgd_preds = sgd_clf.predict_proba(all_cases_features.copy())\n",
    "    sgd_preds = np.multiply(sgd_preds, 100)\n",
    "    sgd_df = pd.DataFrame(sgd_preds, columns=ALL_CASES_PREDICTIONS_COLUMS)\n",
    "    sgd_df[\"TYPE\"] = \"SGD\"\n",
    "    preds_df = preds_df.append(sgd_df)\n",
    "    \n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases_features = load_data(ALL_CASES_INPUT_DATA)\n",
    "all_cases_predictions_df = get_all_cases_predictions(all_cases_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.381089</td>\n",
       "      <td>88.689598</td>\n",
       "      <td>0.595055</td>\n",
       "      <td>0.722388</td>\n",
       "      <td>3.782138</td>\n",
       "      <td>0.533339</td>\n",
       "      <td>0.327221</td>\n",
       "      <td>1.754858</td>\n",
       "      <td>2.289423</td>\n",
       "      <td>0.924888</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.474035</td>\n",
       "      <td>29.048544</td>\n",
       "      <td>4.820099</td>\n",
       "      <td>3.918885</td>\n",
       "      <td>25.696648</td>\n",
       "      <td>4.417932</td>\n",
       "      <td>1.682335</td>\n",
       "      <td>2.958868</td>\n",
       "      <td>6.509285</td>\n",
       "      <td>3.473367</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428024</td>\n",
       "      <td>2.643808</td>\n",
       "      <td>0.489288</td>\n",
       "      <td>0.864877</td>\n",
       "      <td>92.944550</td>\n",
       "      <td>1.276228</td>\n",
       "      <td>0.128378</td>\n",
       "      <td>0.501736</td>\n",
       "      <td>0.375435</td>\n",
       "      <td>0.347664</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.388781</td>\n",
       "      <td>0.991701</td>\n",
       "      <td>0.654110</td>\n",
       "      <td>0.775801</td>\n",
       "      <td>90.135971</td>\n",
       "      <td>3.303822</td>\n",
       "      <td>0.259724</td>\n",
       "      <td>0.644441</td>\n",
       "      <td>0.484932</td>\n",
       "      <td>0.360716</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.507380</td>\n",
       "      <td>39.200539</td>\n",
       "      <td>5.189125</td>\n",
       "      <td>4.014410</td>\n",
       "      <td>10.353764</td>\n",
       "      <td>3.840787</td>\n",
       "      <td>0.860542</td>\n",
       "      <td>2.556046</td>\n",
       "      <td>2.367646</td>\n",
       "      <td>29.109760</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         2         3          4         5         6  \\\n",
       "0   0.381089  88.689598  0.595055  0.722388   3.782138  0.533339  0.327221   \n",
       "1  17.474035  29.048544  4.820099  3.918885  25.696648  4.417932  1.682335   \n",
       "2   0.428024   2.643808  0.489288  0.864877  92.944550  1.276228  0.128378   \n",
       "3   2.388781   0.991701  0.654110  0.775801  90.135971  3.303822  0.259724   \n",
       "4   2.507380  39.200539  5.189125  4.014410  10.353764  3.840787  0.860542   \n",
       "\n",
       "          7         8          9 TYPE  \n",
       "0  1.754858  2.289423   0.924888  MLP  \n",
       "1  2.958868  6.509285   3.473367  MLP  \n",
       "2  0.501736  0.375435   0.347664  MLP  \n",
       "3  0.644441  0.484932   0.360716  MLP  \n",
       "4  2.556046  2.367646  29.109760  MLP  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.305213e-59</td>\n",
       "      <td>6.961097e-49</td>\n",
       "      <td>4.668178e-26</td>\n",
       "      <td>1.032624e-25</td>\n",
       "      <td>2.840106e-75</td>\n",
       "      <td>5.172385e-40</td>\n",
       "      <td>1.708020e-62</td>\n",
       "      <td>1.412779e-75</td>\n",
       "      <td>7.699729e-34</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.639525e-148</td>\n",
       "      <td>9.811718e-56</td>\n",
       "      <td>1.358361e-22</td>\n",
       "      <td>6.992827e-75</td>\n",
       "      <td>6.295976e-94</td>\n",
       "      <td>4.831449e-175</td>\n",
       "      <td>4.517859e-32</td>\n",
       "      <td>1.566642e-87</td>\n",
       "      <td>3.894994e-146</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.174890e-126</td>\n",
       "      <td>7.982212e-136</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>1.544952e-23</td>\n",
       "      <td>1.138255e-100</td>\n",
       "      <td>8.984591e-136</td>\n",
       "      <td>1.205190e-33</td>\n",
       "      <td>3.959178e-06</td>\n",
       "      <td>1.142351e-120</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>9.840145e-107</td>\n",
       "      <td>3.590375e-82</td>\n",
       "      <td>3.040250e-19</td>\n",
       "      <td>1.803035e-50</td>\n",
       "      <td>2.556247e-90</td>\n",
       "      <td>5.883163e-152</td>\n",
       "      <td>4.777214e-102</td>\n",
       "      <td>6.542462e-72</td>\n",
       "      <td>5.270384e-83</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4.364533e-68</td>\n",
       "      <td>1.784362e-66</td>\n",
       "      <td>2.894008e-34</td>\n",
       "      <td>2.647241e-27</td>\n",
       "      <td>5.902223e-26</td>\n",
       "      <td>4.175965e-69</td>\n",
       "      <td>1.106178e-58</td>\n",
       "      <td>4.560587e-68</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.618063e-24</td>\n",
       "      <td>SGD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0              1             2             3             4  \\\n",
       "123   4.305213e-59   6.961097e-49  4.668178e-26  1.032624e-25  2.840106e-75   \n",
       "124   1.000000e+02  2.639525e-148  9.811718e-56  1.358361e-22  6.992827e-75   \n",
       "125  2.174890e-126  7.982212e-136  5.000000e+01  5.000000e+01  1.544952e-23   \n",
       "126   1.000000e+02  9.840145e-107  3.590375e-82  3.040250e-19  1.803035e-50   \n",
       "127   4.364533e-68   1.784362e-66  2.894008e-34  2.647241e-27  5.902223e-26   \n",
       "\n",
       "                 5              6              7             8              9  \\\n",
       "123   5.172385e-40   1.708020e-62   1.412779e-75  7.699729e-34   1.000000e+02   \n",
       "124   6.295976e-94  4.831449e-175   4.517859e-32  1.566642e-87  3.894994e-146   \n",
       "125  1.138255e-100  8.984591e-136   1.205190e-33  3.959178e-06  1.142351e-120   \n",
       "126   2.556247e-90  5.883163e-152  4.777214e-102  6.542462e-72   5.270384e-83   \n",
       "127   4.175965e-69   1.106178e-58   4.560587e-68  1.000000e+02   2.618063e-24   \n",
       "\n",
       "    TYPE  \n",
       "123  SGD  \n",
       "124  SGD  \n",
       "125  SGD  \n",
       "126  SGD  \n",
       "127  SGD  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cases_predictions_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
